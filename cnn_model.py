# -*- coding: utf-8 -*-
"""CNN_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aL5ODW056yqg9ZDHqE3QD1SxKEwtqF-x
"""

#from google.colab import drive
#drive.mount('/content/drive')

#!unzip "/content/drive/MyDrive/unibuc-brain-ad.zip"

from pandas.core.dtypes.common import classes
import cv2
import numpy as np
import glob
import csv
from sklearn.utils import shuffle
import os
import tensorflow as tf


data_path = './data/data'

train_labels = np.genfromtxt('/content/data/train_labels.txt', delimiter=',', dtype='int')[1:]
train_labels = train_labels[:,1]
n_classes = len(np.unique(train_labels))
class_counts = np.bincount(train_labels)
class_priors = class_counts / len(train_labels)


validation_labels = np.genfromtxt('/content/data/validation_labels.txt', delimiter=',', dtype='int')[1:]
validation_labels = validation_labels[:,1]

test_labels = np.genfromtxt('/content/data/sample_submission.txt', delimiter=',', dtype='int')[1:]
test_labels = test_labels[:,1]

# Extracting images in correct order
png_files = sorted(glob.glob(os.path.join(data_path, "*.png")), key=lambda x: int(os.path.basename(x).split(".")[0]))

train_images = []
for path in png_files[:17000]:
    img = cv2.imread(path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # convert to RGB format
    img = np.resize(img, (224,224,3))
    train_images.append(img)
train_images, train_labels = shuffle(train_images, np.concatenate((train_labels, validation_labels),axis=0))

# Load test images
test_images = []
for path in png_files[17000:]:
    img = cv2.imread(path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # convert to RGB format
    img = np.resize(img, (224,224,3))
    test_images.append(img)

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (224, 224,3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation= 'relu'),
    tf.keras.layers.Dense(1, activation = 'sigmoid')
])

from keras import backend as K
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

model.compile(loss = tf.keras.losses.binary_crossentropy, optimizer= tf.keras.optimizers.Adam(), metrics= ["accuracy"])

train_images = np.array(train_images)  # convert train_images to NumPy array
train_labels = np.array(train_labels)
history = model.fit(x=train_images, y=train_labels, epochs = 5)
print(np.shape(train_images), np.shape(train_labels))

test_images = np.array(test_images)
y_pred = (model.predict(test_images) > 0.5).astype("int32")


# accuracy: (tp + tn) / (p + n)
accuracy = accuracy_score(test_labels, y_pred)


# precision tp / (tp + fp)

precision = precision_score(test_labels, y_pred)


# recall: tp / (tp + fn)

recall = recall_score(test_labels, y_pred)


# f1: 2 tp / (2 tp + fp + fn)

f1 = f1_score(test_labels, y_pred)

print(f1)

y_pred = np.concatenate(y_pred, axis=0)
print(y_pred)

ids = np.genfromtxt('/content/data/sample_submission.txt', delimiter=',', dtype='int')[1:][:,0]

with open('cnn_predictions.csv', mode='w', newline='') as csv_file:
    writer = csv.writer(csv_file)
    writer.writerow(['id', 'class'])

    for i in range(len(test_images)):
        prediction = y_pred[i]
        writer.writerow([ids[i], prediction])